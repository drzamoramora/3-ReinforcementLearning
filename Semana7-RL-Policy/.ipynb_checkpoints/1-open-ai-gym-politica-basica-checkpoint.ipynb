{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduccion a Aprendizaje por Refuerzo (RL)\n",
    "\n",
    "**Que es RL?**\n",
    "\n",
    "El aprendizaje por refuerzo (RL) es un área del aprendizaje automático que se ocupa de cómo los agentes inteligentes deben tomar acciones en un entorno para maximizar la noción de recompensa acumulativa.\n",
    "\n",
    "El aprendizaje por refuerzo se diferencia del aprendizaje supervisado en que no necesita que se presenten pares de entrada / salida etiquetados y en que no necesita que se corrijan explícitamente acciones subóptimas. En cambio, la atención se centra en encontrar un equilibrio entre la exploración (de un territorio inexplorado) y la explotación (del conocimiento actual).\n",
    "\n",
    "<a target=\"_blank\" href=\"https://www.thestreet.com/economonitor/financial-markets/new-artificial-intelligence-are-based-on-old-models-of-human-behavior\">RL Chiken</a>\n",
    "\n",
    "\n",
    "**Que son agentes inteligentes?**\n",
    "\n",
    "En inteligencia artificial, un agente inteligente (IA) se refiere a una entidad autónoma que actúa, dirigiendo su actividad hacia el logro de objetivos (es decir, es un agente), sobre un entorno mediante la observación a través de sensores y consecuentes actuadores (es decir, es inteligente). Los agentes inteligentes también pueden aprender o utilizar el conocimiento para lograr sus objetivos. Pueden ser muy simples o muy complejas. Una máquina réflex, como un termostato, se considera un ejemplo de agente inteligente.\n",
    "\n",
    "Estaremos explorando mas teoria de agentes inteligentes en el curso 4, por ahora comprendamos como entrenar uno utilizando aprendizaje por refuerzo.\n",
    "\n",
    "\n",
    "### Tipos de RL\n",
    "\n",
    "Se ha desarrollado varios modelos para enfrentar el problema del RL. Sin embargo 2 de los mas exitosos son RL basado en **politicas (policy gradients)** y **Q Learning** (Q-Networks los cuales incluyen procesos de desicion markovianos).\n",
    "\n",
    "Esta semana estudiaremos el primer tipo: Policy Gradients.\n",
    "\n",
    "### Policy Gradients\n",
    "\n",
    "#### Optimizacion de Premios (rewards)\n",
    "\n",
    "Un agente inteligente realiza observaciones del ambiente, y toma acciones con el fin de obtener un premio. El objetivo final es que el agente maximice estos premios a través del tiempo.\n",
    "\n",
    "El agente inteligente al principio no tiene noción de lo que hace y simplemente reacciona contra el ambiente (random). Conforme para el tiempo t, el agente va recibiendo premios por algunas acciones, que refuerzan el modelo interno (el estado) lo cual ayudan al agente a aprender sobre las acciones que le brindan alguna ganancia. \n",
    "\n",
    "Para iniciar a comprender RL, vamos a desarrollar esto mediante un ejemplo basico de una politica, sin mucha inteligencia. Por el moemento sera suficiente para comprender la idea de las politicas. En nuestro proximo notebook, utilizaremos una politica basada en gradientes, que no solo es mas compleja, sino que tambien da resultados sorprendentes de aprendizaje.\n",
    "\n",
    "### Open AI - GYM\n",
    "\n",
    "Open AI Gym es un conjunto de herramientas para desarrollar y comparar algoritmos de aprendizaje por refuerzo. Es compatible con la enseñanza de los agentes, desde caminar hasta jugar juegos como Pong o Pinball.\n",
    "\n",
    "Vamos a desarrollar nuestr primer codigo para poder balancear un pivote sobre un carrito.\n",
    "\n",
    "https://gym.openai.com/\n",
    "\n",
    "**nuestro problema:**\n",
    "\n",
    "Un poste está unido por una articulación no accionada a un carro, que se mueve a lo largo de una pista sin fricción. El sistema se controla aplicando una fuerza de +1 o -1 al carro. El péndulo comienza en posición vertical y el objetivo es evitar que se caiga. Se proporciona una recompensa de +1 por cada paso de tiempo que el poste permanece en posición vertical. El episodio termina cuando el poste se cae o el carro esta afuera de los limites de la pantalla de juego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge gym\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el ambiente de Cart Pole de Open AI GYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02953907  0.04704494 -0.02461818  0.02147581]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "obs = env.reset()\n",
    "\n",
    "# al hacer reset de ambiente, obtenemos la primera observacion que hace el agente al ambiente. \n",
    "# la observacion es un arreglo con 4 valores\n",
    "print(obs)\n",
    "\n",
    "#    Observation:\n",
    "#        Type: Box(4)\n",
    "#        Num     Observation               Min                     Max\n",
    "#        0       Cart Position             -4.8                    4.8\n",
    "#        1       Cart Velocity             -Inf                    Inf\n",
    "#        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "#        3       Pole Angular Velocity     -Inf                    Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18d337b60b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = env.render(mode=\"rgb_array\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available actions in the environment \n",
    "\n",
    "# 0 for accelerate left and 1 to right.\n",
    "env.action_space\n",
    "\n",
    "# Type: Discrete(2)\n",
    "# Num   Action\n",
    "# 0     Push cart to the left\n",
    "# 1     Push cart to the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de aceleracion hacia la derecha (un solo step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs [-0.02859817  0.24251113 -0.02418866 -0.27887165]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18d33ac1630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "action = 1 # mueva hacia la derecha\n",
    "\n",
    "# pasamos la accion al ambiente (donde esta el agente)\n",
    "# esto devuelve los parametros del abiente\n",
    "obs, reward, done, info = env.step(action)\n",
    "\n",
    "print(\"obs\", obs) # la nueva observacion\n",
    "print(\"reward\", reward) # si no se cae el palo, da un premio = 1\n",
    "print(\"done\", done) #  indica si se murio el agente. osea el palo se cayo\n",
    "print(\"info\", info) # variable para devolver algun dato custom (no usado por el momento)\n",
    "\n",
    "img = env.render(mode=\"rgb_array\")\n",
    "plt.imshow(img)\n",
    "\n",
    "# [-0.02953907  0.04704494 -0.02461818  0.02147581]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algopritmo de Politica Basica\n",
    "\n",
    "El carro acelera hacia la izquierda si el poste se inclina hacia la izquierda y viceversa.\n",
    "\n",
    "Nuestro objetivo es desarrollar un algoritmo que permita maximizar los premios a traves del tiempo.\n",
    "Vamos a acumular los premios por episodio en nuestro vector de premios (totals).\n",
    "\n",
    "Vamos a realizar varias simulaciones (episodes) para entrenar el modelo, donde en cada episodio hay un total de premios (episode_rewards) el cual vamos a reiniciar en cada episodio nuevo. Cada episodio esta compuesto por un conjunto de pasos.\n",
    "\n",
    "Pensemos en el episodio como un epoch, y el cada paso como un step de cuando entrenamos un algoritmo de ML supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 43.034\n",
      "std 9.262874499851545\n",
      "min 24.0\n",
      "max 72.0\n"
     ]
    }
   ],
   "source": [
    "def basic_policy(obs):\n",
    "    angle = obs[2] # angulo del poste\n",
    "    return 0 if angle < 0 else 1\n",
    "\n",
    "totals = []\n",
    "for episode in range(500):\n",
    "    episode_rewards = 0\n",
    "    obs = env.reset()\n",
    "    for step in range(200):\n",
    "        action = basic_policy(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    totals.append(episode_rewards)\n",
    "    env.render()\n",
    "    \n",
    "print(\"mean\",np.mean(totals))\n",
    "print(\"std\",np.std(totals))\n",
    "print(\"min\",np.min(totals))\n",
    "print(\"max\",np.max(totals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max cuenta que con 500 episodios, que la política nunca logró enderezar el poste durante más de X pasos. (por ejemplo max = 66).\n",
    "\n",
    "**nota importante**: la funcion basic policy no aprende. Solo reacciona. En nuestro proximo notebook, vamos a modificar esto (drasticamente) para que el agente pueda aprender de la experiencia (de los episodios y steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
