{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos secuenciales markovianos\n",
    "\n",
    "Ahora estudiaremos otra modalidad de NLP, que es el modelado de secuencias categóricas. \n",
    "\n",
    "Hasta ahora hemos trabajado con bag-of-words, un modelo en el que se pierde la **información secuencial**, es decir, el orden en el que vienen las palabras. Estudiaremos uno de los modelos secuenciales más populares: el modelo oculto de Markov. \n",
    "\n",
    "## La cadena de Markov\n",
    "\n",
    "Una cadena de Markov formaliza las probabilidades de cambio de estados en un sistema no determinístico. Por ejemplo, supongamos que nuestro sistema es el clima de nuestra localidad, y puede estar en dos estados dependiendo del día: \"Lluvioso\" (estado ``L``) y \"Soleado\" (estado ``S``). Observamos empíricamente la siguiente secuencia de estados cada día por 30 días:\n",
    "\n",
    "``S, S, L, S, S, L, L, S, S, S, L, L, L, S, S, S, S, L, S, L, S, S, L, S, S, L, L, S, S, L``\n",
    "\n",
    "Existen cuatro transiciones posibles: ``S`` $\\rightarrow$ ``S``, ``S`` $\\rightarrow$ ``L``, ``L`` $\\rightarrow$ ``L`` y ``L`` $\\rightarrow$ ``S``. En general, el número de transiciones en una cadena de Markov es de $M^2$ donde $M$ es el número de estados. Las cadenas de Markov cumplen con la llamada **propiedad de Markov**, que dice que, si estamos en un estado $t$, cualquier predicción sobre un estado futuro se hace con base en el estado $t$ y no en la historia completa de estados anteriores. \n",
    "\n",
    "Vamos a calcular una matriz de conteos con la secuencia anterior, donde contamos el número de veces que cada transición se da (se toma el índice de fila como el \"antes\", y el de la columna el \"después\"):\n",
    "\n",
    "| | ``L`` | ``S`` |\n",
    "|---|---|---|\n",
    "| ``L`` | 4 | 7 |\n",
    "| ``S`` | 8 | 10 |\n",
    "\n",
    "Esta matriz la convertimos en una **matriz de transición** dividiendo cada valor el total **de su fila**\n",
    "\n",
    "| | ``L`` | ``S`` |\n",
    "|---|---|---|\n",
    "| ``L`` | 0.36 | 0.64 |\n",
    "| ``S`` | 0.44 | 0.56 |\n",
    "\n",
    "De modo que **la suma de cada fila da 1**. En forma gráfica, esta cadena se representaría del siguiente modo:\n",
    "\n",
    "<img src=\"resources/mc1.png\">\n",
    "\n",
    "La podemos interpretar de la siguiente manera: **si hoy es un día lluvioso, la probabilidad de que mañana llueva es del 36% y del 64% que sea soleado; asimismo, si hoy es un día soleado, la probabilidad de que mañana llueva es del 44% y del 56% de mantenerse soleado**.\n",
    "\n",
    "## Modelos ocultos de Markov (HMM)\n",
    "\n",
    "Continuemos con nuestro ejemplo del clima. Supongamos que, en vez de tener datos sobre si hace o no un día lluvioso, tenemos datos sobre la ropa que una persona se ha puesto cada día, la cual puede ser ``saco``, ``jacket``, ``shorts``, ``bikini``, o ``jeans``. Sabemos bien que el tipo de prenda que una persona escoge está en función del clima que hace afuera, por lo cual podríamos inferir el tipo de clima que hace en base al tipo de prendas observadas. \n",
    "\n",
    "Aquí entra **el modelo oculto de Markov**, que es un modelo secuencial Markoviano pero aumentado con **una capa adicional** de **estados ocultos**. Los llamamos \"ocultos\" porque funcionan como una **variable latente**, que a pesar de que se pueden \"ver\" en los datos dichos estados **no hay un etiquetado explícito** en ellos.\n",
    "\n",
    "Volviendo a nuestro ejemplo, tenemos nuestros datos con cinco tipos de observaciones (prendas), pero también vamos a decir que tenemos **dos** estados ocultos: \"lluvioso\" y \"soleado\" (esta decisión la tomamos por observación). El modelo resultante tendría dos niveles:\n",
    "\n",
    "1. El nivel **latente**, en donde nos podemos mover entre el estado oculto ``L`` (\"lluvioso\") y el estado oculto ``S`` (\"soleado\"), y modelamos las **probabilidades de transición** de movernos entre ``L`` y ``S``.\n",
    "\n",
    "2. El nivel **observado**, en donde tenemos las posibles observaciones (``saco``, ``jacket``, ``shorts``, ``bikini`` y ``jeans``) con las probabilidades de que aparezcan, las cuales vienen condicionadas a los estados latentes en los que estamos y se conocen **probabilidades de emisión**. Básicamente, son de la forma \"probabilidad de que mañana llueva dado que estamos en el estado invierno\".  \n",
    "\n",
    "Veámoslo gráficamente:\n",
    "\n",
    "<img src=\"resources/mc2.png\">\n",
    "\n",
    "Aquí, los círculos representan estados latentes y los cuadrados observaciones. Las líneas sólidas representan probabilidades de transición y las líneas punteadas representan probabilidades de emisión. \n",
    "\n",
    "Adicionalmente, también hay un \"nivel cero\" donde tenemos la probabilidad de comienzo, es decir, la probabilidad de que el primer estado de la secuencia sea un estado latente determinado. \n",
    "\n",
    "### Aprendiendo el HMM con ``hmmlearn``\n",
    "\n",
    "La biblioteca ``scikit-learn`` tenía originalmente HMMs, pero se movieron por completo al paquete ``hmmlearn``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63871414 0.36128586]\n",
      " [0.17763275 0.82236725]]\n",
      "\n",
      "Emisión estado 1:  {'bikini': 0.0002020312802641571, 'jacket': 0.1187653931740253, 'jeans': 0.4927839598111551, 'saco': 0.3880955106637636, 'shorts': 0.0001531050707918985} \n",
      "\n",
      "Emisión estado 2:  {'bikini': 0.4927661500547384, 'jacket': 0.04924810698057497, 'jeans': 0.040301046357194135, 'saco': 0.0037528579297541323, 'shorts': 0.41393183867773836} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1        -536.0233             +nan\n",
      "         2        -454.1729         +81.8503\n",
      "         3        -454.1383          +0.0347\n",
      "         4        -454.1012          +0.0371\n",
      "         5        -454.0601          +0.0411\n",
      "         6        -454.0133          +0.0469\n",
      "         7        -453.9588          +0.0544\n",
      "         8        -453.8945          +0.0643\n",
      "         9        -453.8172          +0.0774\n",
      "        10        -453.7220          +0.0951\n",
      "        11        -453.6021          +0.1199\n",
      "        12        -453.4470          +0.1551\n",
      "        13        -453.2415          +0.2055\n",
      "        14        -452.9631          +0.2785\n",
      "        15        -452.5791          +0.3840\n",
      "        16        -452.0441          +0.5350\n",
      "        17        -451.2987          +0.7455\n",
      "        18        -450.2765          +1.0221\n",
      "        19        -448.9293          +1.3473\n",
      "        20        -447.2717          +1.6576\n",
      "        21        -445.4208          +1.8509\n",
      "        22        -443.5631          +1.8578\n",
      "        23        -441.8411          +1.7219\n",
      "        24        -440.2865          +1.5547\n",
      "        25        -438.8756          +1.4109\n",
      "        26        -437.6044          +1.2712\n",
      "        27        -436.4942          +1.1102\n",
      "        28        -435.5649          +0.9293\n",
      "        29        -434.8190          +0.7459\n",
      "        30        -434.2419          +0.5771\n",
      "        31        -433.8084          +0.4336\n",
      "        32        -433.4899          +0.3185\n",
      "        33        -433.2598          +0.2300\n",
      "        34        -433.0957          +0.1641\n",
      "        35        -432.9797          +0.1160\n",
      "        36        -432.8982          +0.0815\n",
      "        37        -432.8413          +0.0569\n",
      "        38        -432.8016          +0.0397\n",
      "        39        -432.7740          +0.0276\n",
      "        40        -432.7548          +0.0192\n",
      "        41        -432.7414          +0.0134\n",
      "        42        -432.7320          +0.0094\n"
     ]
    }
   ],
   "source": [
    "#!conda install -c conda-forge hmmlearn\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# secuencia de observaciones\n",
    "x = ['jeans', 'jeans', 'jacket', 'jeans', 'shorts', 'shorts', 'shorts', 'jacket', 'jeans', 'saco', 'shorts', 'bikini', 'shorts', 'jacket', 'shorts', 'bikini', 'bikini', 'shorts', 'saco', 'bikini', 'shorts', 'shorts', 'jacket', 'jeans', 'jeans', 'saco', 'bikini', 'bikini', 'bikini', 'bikini', 'shorts', 'shorts', 'jacket', 'bikini', 'shorts', 'bikini', 'bikini', 'jacket', 'saco', 'jeans', 'jacket', 'jeans', 'bikini', 'bikini', 'bikini', 'jeans', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'jeans', 'shorts', 'bikini', 'bikini', 'shorts', 'jeans', 'bikini', 'shorts', 'bikini', 'saco', 'jeans', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'shorts', 'bikini', 'shorts', 'saco', 'bikini', 'shorts', 'bikini', 'shorts', 'saco', 'jeans', 'saco', 'jacket', 'saco', 'shorts', 'bikini', 'bikini', 'saco', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'jacket', 'shorts', 'bikini', 'bikini', 'shorts', 'jeans', 'bikini', 'bikini', 'shorts', 'saco', 'jeans', 'jeans', 'jeans', 'bikini', 'shorts', 'shorts', 'shorts', 'shorts', 'bikini', 'jeans', 'shorts', 'shorts', 'bikini', 'shorts', 'jeans', 'saco', 'jeans', 'jeans', 'saco', 'bikini', 'shorts', 'bikini', 'saco', 'jeans', 'jeans', 'bikini', 'shorts', 'shorts', 'jeans', 'bikini', 'bikini', 'bikini', 'shorts', 'jeans', 'shorts', 'shorts', 'bikini', 'jacket', 'jeans', 'jeans', 'jeans', 'shorts', 'bikini', 'shorts', 'bikini', 'shorts', 'bikini', 'jacket', 'bikini', 'bikini', 'bikini', 'bikini', 'jeans', 'jeans', 'jeans', 'jacket', 'jeans', 'shorts', 'shorts', 'shorts', 'jacket', 'jeans', 'saco', 'shorts', 'bikini', 'shorts', 'jacket', 'shorts', 'bikini', 'bikini', 'shorts', 'saco', 'bikini', 'shorts', 'shorts', 'jacket', 'jeans', 'jeans', 'saco', 'bikini', 'bikini', 'bikini', 'bikini', 'shorts', 'shorts', 'jacket', 'bikini', 'shorts', 'bikini', 'bikini', 'jacket', 'saco', 'jeans', 'jacket', 'jeans', 'bikini', 'bikini', 'bikini', 'jeans', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'jeans', 'shorts', 'bikini', 'bikini', 'shorts', 'jeans', 'bikini', 'shorts', 'bikini', 'saco', 'jeans', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'shorts', 'bikini', 'shorts', 'saco', 'bikini', 'shorts', 'bikini', 'shorts', 'saco', 'jeans', 'saco', 'jacket', 'saco', 'shorts', 'bikini', 'bikini', 'saco', 'saco', 'saco', 'bikini', 'bikini', 'shorts', 'jacket', 'shorts', 'bikini', 'bikini', 'shorts', 'jeans', 'bikini', 'bikini', 'shorts', 'saco', 'jeans', 'jeans', 'jeans', 'bikini', 'shorts', 'shorts', 'shorts', 'shorts', 'bikini', 'jeans', 'shorts', 'shorts', 'bikini', 'shorts', 'jeans', 'saco', 'jeans', 'jeans', 'saco', 'bikini', 'shorts', 'bikini', 'saco', 'jeans', 'jeans', 'bikini', 'shorts', 'shorts', 'jeans', 'bikini', 'bikini', 'bikini', 'shorts', 'jeans', 'shorts', 'shorts', 'bikini', 'jacket', 'jeans', 'jeans', 'jeans', 'shorts', 'bikini', 'shorts', 'bikini', 'shorts', 'bikini', 'jacket', 'bikini', 'bikini', 'bikini', 'bikini', 'jeans']\n",
    "\n",
    "# LabelEncoder para codificar la secuencia en enteros {0, 1, 2, 3, 4}\n",
    "enc = LabelEncoder().fit(x)\n",
    "\n",
    "# codificamos la secuencia en un arreglo de enteros\n",
    "x_enc = enc.transform(x).reshape(1, -1)\n",
    "\n",
    "# entrenamos el modelo\n",
    "model = hmm.MultinomialHMM(n_components=2, n_iter=100, verbose=True).fit(x_enc)\n",
    "\n",
    "# veamos las probabilidades de transmisión entre estados\n",
    "print(model.transmat_)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# y las probabilidades de emisión\n",
    "print('Emisión estado 1: ', dict(zip(enc.classes_, model.emissionprob_[0])), '\\n')\n",
    "print('Emisión estado 2: ', dict(zip(enc.classes_, model.emissionprob_[1])), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# imprimimos los estados decodificados para cada valor en la secuencia\n",
    "seq_dec = model.decode(x_enc.T)[1]\n",
    "print(seq_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando secuencias a partir de un HMM\n",
    "\n",
    "Además de la predicción, una de las aplicaciones más comunes de modelos secuenciales (desde HMMs hasta redes neuronales recurrentes) es la generación de contenido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -2900.9828             +nan\n",
      "         2       -2548.7830        +352.1998\n",
      "         3       -2548.3982          +0.3848\n",
      "         4       -2547.5124          +0.8858\n",
      "         5       -2545.4466          +2.0657\n",
      "         6       -2540.8489          +4.5977\n",
      "         7       -2532.1051          +8.7438\n",
      "         8       -2520.1036         +12.0015\n",
      "         9       -2508.5195         +11.5841\n",
      "        10       -2497.8957         +10.6237\n",
      "        11       -2486.3745         +11.5212\n",
      "        12       -2473.4790         +12.8955\n",
      "        13       -2460.7724         +12.7066\n",
      "        14       -2450.0104         +10.7619\n",
      "        15       -2441.4104          +8.6001\n",
      "        16       -2433.8936          +7.5168\n",
      "        17       -2428.0020          +5.8915\n",
      "        18       -2424.1839          +3.8181\n",
      "        19       -2420.9943          +3.1896\n",
      "        20       -2417.8960          +3.0983\n",
      "        21       -2415.6856          +2.2104\n",
      "        22       -2414.5051          +1.1805\n",
      "        23       -2413.7979          +0.7072\n",
      "        24       -2413.3017          +0.4962\n",
      "        25       -2412.8608          +0.4410\n",
      "        26       -2412.3398          +0.5210\n",
      "        27       -2411.6787          +0.6610\n",
      "        28       -2410.9587          +0.7201\n",
      "        29       -2410.3536          +0.6051\n",
      "        30       -2409.9656          +0.3880\n",
      "        31       -2409.7644          +0.2012\n",
      "        32       -2409.6703          +0.0940\n",
      "        33       -2409.6256          +0.0447\n",
      "        34       -2409.6019          +0.0237\n",
      "        35       -2409.5872          +0.0147\n",
      "        36       -2409.5764          +0.0108\n",
      "        37       -2409.5675          +0.0089\n"
     ]
    }
   ],
   "source": [
    "citas = [\n",
    "    'Todo lo que ves aquí fue construido por mi abuelo',\n",
    "    'Mi abuelo construyó todo lo que ves aquí',\n",
    "    'Este proyecto de ley será enviado por nuestro presidente al Congreso',\n",
    "    'Nuestro presidente enviará este proyecto de ley al Congreso',\n",
    "    'La mantelería ha sido traída especialmente de Bélgica', \n",
    "    'Trajeron la mantelería especialmente de Bélgica',\n",
    "    'Todo el dinero fue depositado el día acordado',\n",
    "    'Depositaron todo el dinero el día acordado',\n",
    "    'El gato es alimentado, bañado y paseado por mi mujer',\n",
    "    'Mi mujer alimenta, baña y pasea al gato',\n",
    "    'El partido será relatado por los mejores periodistas del canal',\n",
    "    'Los mejores periodistas del canal relatarán el partido',\n",
    "    'El auto tuvo que ser reparado por mi mecánico de mayor confianza',\n",
    "    'Mi mecánico de mayor confianza tuvo que reparar el auto',\n",
    "    'Toneladas de basura son desperdiciadas diariamente en nuestra ciudad', \n",
    "    'Se desperdician diariamente toneladas de basura en nuestra ciudad',\n",
    "    'La primera pizza con ananá fue inventada aquí',\n",
    "    'Aquí se inventó la primera pizza con ananá',\n",
    "    'Todo el cronograma fue entregado por los profesores en tiempo y forma', \n",
    "    'Los profesores entregaron todo el cronograma en tiempo y forma',\n",
    "    'Las próximas cuotas serán abonadas alrededor del día quince', \n",
    "    'Abonarán las próximas cuotas alrededor del día quince',\n",
    "    'La ropa de la reina ha sido confeccionada por un diseñador de modas',\n",
    "    'Un diseñador de modas confeccionó la ropa de la reina',\n",
    "    'Este departamento es vendido a una cifra irrisoria',\n",
    "    'Venden este departamento a una cifra irrisoria',\n",
    "    'El mecánico fue instruido en la universidad',\n",
    "    'Instruyeron al mecánico en la universidad',\n",
    "    'El juego ha sido inventado por los mayas', \n",
    "    'Los mayas inventaron el juego',\n",
    "    'El monumento fue construido en honor al ídolo nacional',\n",
    "    'Construyeron el monumento en honor al ídolo nacional',\n",
    "    'La inflación de julio fue superada por la de agosto',\n",
    "    'La de agosto superó a la inflación de julio',\n",
    "    'El cese al fuego fue declarado por las dos naciones al mismo tiempo',\n",
    "    'Declararon el cese al fuego por las dos naciones al mismo tiempo',\n",
    "    'Las camisas son entregadas día a día, limpias y planchadas',\n",
    "    'Entregan día a día las camisas limpias y planchadas',\n",
    "    'La computadora más potente fue construida con tecnología de punta', \n",
    "    'Construyeron la computadora más potente con tecnología de punta',\n",
    "    'Esa taza fue fabricada en 1932',\n",
    "    'Fabricaron esa taza en 1932',\n",
    "    'El piano más caro del mundo fue comprado en Australia',\n",
    "    'Compraron el piano más caro del mundo en Australia',\n",
    "    'El periódico fue denunciado por calumnias e injurias',\n",
    "    'Denunciaron por calumnias e injurias al periódico',\n",
    "    'El equipo francés fue derrotado en cuartos de final',\n",
    "    'Derrotaron al equipo francés en cuartos de final',\n",
    "    'El tesoro ha sido encontrado por el perro',\n",
    "    'El perro encontró el tesoro',\n",
    "    'Algunas palabras han sido extraídas del libro', \n",
    "    'Extrajeron algunas palabras del libro',\n",
    "    'El gol fue anotado por nuestro mejor jugador',\n",
    "    'Nuestro mejor jugador anotó el gol',\n",
    "    'Cuarenta millones de dólares fueron entregados al ganador de la lotería',\n",
    "    'Entregaron cuarenta millones de dólares al ganador de la lotería',\n",
    "    'El regalo a mi madre fue comprado el mismo día de su cumpleaños',\n",
    "    'Compraron el regalo de mi madre el mismo día de su cumpleaños',\n",
    "    'Dos kilos de narcóticos han sido incautados por la policía en el día de hoy', \n",
    "    'La policía incautó dos kilos de narcóticos'\n",
    "]\n",
    "\n",
    "citas = [ cita.lower().split() for cita in citas ]\n",
    "\n",
    "# codificamos\n",
    "enc = LabelEncoder().fit([y for l in citas for y in l])\n",
    "citas_enc = np.concatenate([enc.transform(y).reshape(-1, 1) for y in citas])\n",
    "citas_len = [len(y) for y in citas] # largo de cada cita\n",
    "\n",
    "# modelo de citas\n",
    "citas_model = hmm.MultinomialHMM(n_iter=200, n_components=2, verbose=True).fit(citas_enc, citas_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un taza canal\n",
      "alimenta, presidente a\n",
      "día cuarenta palabras superó hoy\n",
      "ves por ley diariamente primera día la\n",
      "un dinero libro fue periódico día cumpleaños con de injurias\n",
      "fuego presidente pasea potente día de final superada su la por inflación cuartos por computadora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPC\\anaconda3\\envs\\TF23-RL\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(enc.inverse_transform(citas_model.sample(3)[0])))\n",
    "print(' '.join(enc.inverse_transform(citas_model.sample(3)[0])))\n",
    "print(' '.join(enc.inverse_transform(citas_model.sample(5)[0])))\n",
    "print(' '.join(enc.inverse_transform(citas_model.sample(7)[0])))\n",
    "print(' '.join(enc.inverse_transform(citas_model.sample(10)[0])))\n",
    "print(' '.join(enc.inverse_transform(citas_model.sample(15)[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
